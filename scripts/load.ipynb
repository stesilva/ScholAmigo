{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567dbb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, logging, boto3\n",
    "from pathlib import Path\n",
    "from pyspark.sql import SparkSession, functions as F, Window\n",
    "from pyspark.sql.types import *\n",
    "from textwrap import dedent\n",
    "\n",
    "PG = dict(\n",
    "    host=\"localhost\",\n",
    "    port=5436,\n",
    "    dbname=\"scholarships\",\n",
    "    user=\"scholarships\",\n",
    "    password=\"scholar_pw\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43664947",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"jdbc:postgresql://{PG['host']}:{PG['port']}/{PG['dbname']}\"\n",
    "pg_props = {\n",
    "    \"user\":     PG[\"user\"],\n",
    "    \"password\": PG[\"password\"],\n",
    "    \"driver\":   \"org.postgresql.Driver\",\n",
    "    # let Postgres treat text as text, json as json\n",
    "    \"stringtype\": \"unspecified\",\n",
    "}\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b03f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target schema\n",
    "\n",
    "TARGET_SCHEMA = StructType([\n",
    "    StructField(\"scholarship_id\",        StringType(), False),\n",
    "    StructField(\"scholarship_name\",      StringType(), True),\n",
    "    StructField(\"description\",           StringType(), True),\n",
    "    StructField(\"program_country\",       ArrayType(StringType()), True),\n",
    "    StructField(\"origin_country\",        ArrayType(StringType()), True),\n",
    "    StructField(\"program_level\",         StringType(), True),\n",
    "    StructField(\"required_level\",        StringType(), True),\n",
    "    StructField(\"intake\",                StringType(), True),\n",
    "    StructField(\"documents\",             StringType(), True),\n",
    "    StructField(\"website\",               StringType(), True),\n",
    "    StructField(\"last_updated_utc\",      StringType(), True),\n",
    "    StructField(\"funding_category\",      StringType(), True),\n",
    "    StructField(\"deadline\",              StringType(), True),\n",
    "    StructField(\"scholarship_coverage\",  MapType(StringType(), StringType()), True),\n",
    "    StructField(\"language_certificates\", MapType(StringType(), StringType()), True),\n",
    "    StructField(\"fields_of_study_code\",  ArrayType(StringType()), True),\n",
    "    StructField(\"study_duration\",        StringType(), True),\n",
    "    StructField(\"gpa\",                   StringType(), True),\n",
    "    StructField(\"list_of_universities\",  ArrayType(StringType()), True),\n",
    "    StructField(\"status\",                StringType(), True),\n",
    "    StructField(\"other_information\",     MapType(StringType(), StringType()), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f73ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_PROFILE       = \"bdm-2025\"\n",
    "os.environ[\"AWS_PROFILE\"] = AWS_PROFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "476ad96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:34:36 WARN Utils: Your hostname, MacBook-Pro-Olha.local resolves to a loopback address: 127.0.0.1; using 192.168.1.156 instead (on interface en0)\n",
      "25/06/08 22:34:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/olhabaliasina/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/olhabaliasina/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.amazonaws#aws-java-sdk-bundle added as a dependency\n",
      "org.postgresql#postgresql added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-03c82112-54f2-462f-96a9-fb2b318ec219;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/olhabaliasina/Documents/BDMA/2nd_semester/Big_Data_Management/Project/ScholAmigo/.venv/lib/python3.13/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.665 in central\n",
      "\tfound org.postgresql#postgresql;42.7.3 in central\n",
      "\tfound org.checkerframework#checker-qual;3.42.0 in central\n",
      ":: resolution report :: resolve 134ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.665 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.42.0 from central in [default]\n",
      "\torg.postgresql#postgresql;42.7.3 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.665] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   6   |   0   |   0   |   1   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-03c82112-54f2-462f-96a9-fb2b318ec219\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/3ms)\n",
      "25/06/08 22:34:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/08 22:34:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/08 22:34:37 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(\"LoadParquetToPG\")\n",
    "         # to switch later - when go to cluster\n",
    "         .master(os.getenv(\"SPARK_MASTER\",\"local[*]\")) # num threads = CPU count\n",
    "         # only driver settings matter in local mode\n",
    "         .config(\"spark.driver.memory\",\"4g\")\n",
    "         # jars for S3 and Postgres\n",
    "         .config(\"spark.jars.packages\",\n",
    "                 \"org.apache.hadoop:hadoop-aws:3.3.4,\"\n",
    "                 \"com.amazonaws:aws-java-sdk-bundle:1.12.665,\"\n",
    "                 \"org.postgresql:postgresql:42.7.3\")\n",
    "         .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\",\n",
    "                 \"com.amazonaws.auth.profile.ProfileCredentialsProvider\")\n",
    "         .config(\"spark.hadoop.fs.s3a.aws.profile\",AWS_PROFILE)\n",
    "         .getOrCreate())\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2396e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest_dataset_prefix(s3, bucket, prefix):\n",
    "    \"\"\"Return S3 prefix that ends with ..._YYYY-MM_...parquet not a part-file.\"\"\"\n",
    "    resp = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "    folders = [\n",
    "        obj[\"Key\"].rsplit(\"/\", 1)[0]   # strip /part-000xx…\n",
    "        for obj in resp.get(\"Contents\", [])\n",
    "        if obj[\"Key\"].endswith(\"_SUCCESS\")\n",
    "    ]\n",
    "    if not folders:\n",
    "        raise FileNotFoundError(f\"No parquet datasets under {prefix}\")\n",
    "    # last modified of the _SUCCESS object == dataset timestamp\n",
    "    latest = max(\n",
    "        (o for o in resp[\"Contents\"] if o[\"Key\"].endswith(\"_SUCCESS\")),\n",
    "        key=lambda o: o[\"LastModified\"],\n",
    "    )[\"Key\"].rsplit(\"/\", 1)[0]\n",
    "    return latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93d4cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e87b96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"bucket\"] = \"scholarship-data-trusted\"\n",
    "args[\"prefix\"] = \"erasmus_scholarships_standardized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca8968b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:34:39 | INFO | Found credentials in shared credentials file: ~/.aws/credentials\n",
      "22:34:40 | INFO | Reading dataset s3a://scholarship-data-trusted/erasmus_scholarships_standardized/2025-06_erasmus_scholarship_data_std.parquet\n"
     ]
    }
   ],
   "source": [
    "s3     = boto3.Session(profile_name=AWS_PROFILE).client(\"s3\")\n",
    "prefix = args[\"prefix\"] if args[\"prefix\"].endswith(\"/\") else args[\"prefix\"] + \"/\"\n",
    "key    = latest_dataset_prefix(s3, args[\"bucket\"], prefix)\n",
    "src    = f\"s3a://{args[\"bucket\"]}/{key}\"\n",
    "logging.info(f\"Reading dataset {src}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db382d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = spark.read.schema(TARGET_SCHEMA).parquet(src)\n",
    "\n",
    "df = (\n",
    "    df_raw\n",
    "      .withColumn(\"funding_category\", F.lower(\"funding_category\"))\n",
    "      .withColumn(\"program_level\",    F.lower(\"program_level\"))\n",
    "      .withColumn(\"required_level\",   F.lower(\"required_level\"))\n",
    "      .withColumn(\"intake\",           F.lower(\"intake\"))\n",
    "      .withColumn(\"status\",           F.lower(\"status\"))\n",
    "      .withColumn(\"last_updated_utc\", F.to_timestamp(\"last_updated_utc\",\"dd/MM/yyyy HH:mm\"))\n",
    "      .withColumn(\"deadline\",         F.to_date(\"deadline\",\"dd/MM/yyyy\"))\n",
    "      # maps → json strings for JSONB columns in Postgres\n",
    "      .withColumn(\"scholarship_coverage\",  F.to_json(\"scholarship_coverage\"))\n",
    "      .withColumn(\"language_certificates\", F.to_json(\"language_certificates\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "599c4f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df = df.select(\n",
    "    \"scholarship_id\",\"funding_category\",\"program_level\",\n",
    "    \"required_level\",\"intake\",\"status\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3807a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = df.select(\n",
    "    \"scholarship_id\",\"scholarship_name\",\"description\",\"program_country\",\"origin_country\",\n",
    "    \"documents\",\"website\",\"last_updated_utc\",\"deadline\",\n",
    "    \"scholarship_coverage\",\"language_certificates\",\n",
    "    \"fields_of_study_code\",\"study_duration\",\"gpa\",\n",
    "    \"list_of_universities\",\"other_information\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29959dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark master : local[*]\n",
      "Driver host  : 192.168.1.156\n"
     ]
    }
   ],
   "source": [
    "print(\"Spark master :\", spark.sparkContext.master)\n",
    "print(\"Driver host  :\", spark.conf.get(\"spark.driver.host\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc1fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_dim = spark.read.jdbc(\n",
    "    url=url,\n",
    "    table=\"(SELECT country_id, lower(name) AS name FROM countries) AS c\",\n",
    "    properties=pg_props\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8514f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_country_df = (\n",
    "    df.select(\"scholarship_id\", F.explode(\"program_country\").alias(\"name\"))\n",
    "      .withColumn(\"name\", F.lower(F.trim(\"name\")))\n",
    "      .join(countries_dim,\"name\")\n",
    "      .select(\"scholarship_id\",\"country_id\").distinct()\n",
    ")\n",
    "\n",
    "orig_country_df = (\n",
    "    df.select(\"scholarship_id\", F.explode(\"origin_country\").alias(\"name\"))\n",
    "      .withColumn(\"name\", F.lower(F.trim(\"name\")))\n",
    "      .join(countries_dim,\"name\")\n",
    "      .select(\"scholarship_id\",\"country_id\").distinct()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d58f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fos_df = (\n",
    "    df.select(\"scholarship_id\", F.explode(\"fields_of_study_code\")\n",
    "                             .alias(\"field_code\"))\n",
    "      .distinct()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a68bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(df, table):\n",
    "    df.write \\\n",
    "      .mode(\"append\") \\\n",
    "      .option(\"batchsize\", 1000) \\\n",
    "      .jdbc(url, table, properties=pg_props)\n",
    "\n",
    "save(filter_df,              \"scholarship_filter\")\n",
    "save(info_df,                \"scholarship_info\")\n",
    "save(prog_country_df,        \"program_country\")\n",
    "save(orig_country_df,        \"origin_country\")\n",
    "save(fos_df,                 \"scholarship_field_of_study\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "logging.info(\"PostgreSQL load finished\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28209557",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45abfce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca6797d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4576ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1b6181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251d0586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941bbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a0701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96019e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e5eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
